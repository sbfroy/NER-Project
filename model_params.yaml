model:
  model_name: 'ltg/norbert2' # 'google-bert/bert-base-uncased'
  dropout: 0.45 # 0.15

training:
  batch_size: 32
  num_epochs: 5
  learning_rate: 0.00003

data:
  max_seq_len: 40
  

general:
  seed: 42
  